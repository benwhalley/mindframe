One issue (especially when using COT) is for LLMs to "gild the lilly" or try to do too much.

This might be something for a fine-tune to improve. But to create synthetic data
we might also want to introduce the concept of an "output filter" when generating utterances to return to the client.

https://chatgpt.com/share/670e1659-76a4-8001-9b48-236d76b70e5b