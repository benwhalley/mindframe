
# Mindframe prompting syntax

## TLDR

Prompts are written in plain text/markdown, with some additional
tags for dynamic content, like conversation history or extracted data.

An example prompt for a step:

```
You are an expert in behaviour change.
You and the client are working on {{data.problem.summary}}.

These are some examples which might be relevant:
{% examples data.problem.summary %}

This is your professional formualtion of the case so far:
{{data.formulation}}

This is what has been said recently (last N turns of the conversation):
{% turns %}

Think about what you would say next. Consider all perspectives:
[[think:approach]]

Now, say something to the client. Keep it simple.
[[speak:response]]

```


And for a Judgement with the variable name `step_judgement`:

```
You are a clinical psychologist working
with a client on {{data.problem}}.

This is a summary of what has been said so far:
{{data.step_judgement.summary|default:"No summary available"}}


This is the most recent conversation between you and the client:

{% turns n=10 %}

Update the conversation summary with any new information:

[[summary]]


Does the client show willingness to engage in treatment:

[[pick:willingness|yes,no,unclear]]

Is the client displaying risky behaviour or threatening self-harm?

[[boolean:risk]]

```


Notice that multiple responses can be requested from the AI, using `[[response]]` tags. Details of the different prefixes for responsess (like `pick` and `boolean`) are explained below.



# Detailed syntax guide

Prompts for steps and judgements are written in a simple markdown format,
with some additional tags for dynamic content.

There are 4 main features of the syntax:

1. Including conversation history, with the `{% turns %}` tag
3. Prompting the LLM for a completion, using the `[[label]]` syntax
3. Referring to data from Judgements, using the `{{data.variable_name}}` syntax
4. Including relevant examples from reference materials (TBC)

The prompt syntax is the same whether we are writing a Step or Judgement prompt.


###  Including conversation history using `turns`

It's always important to be able to include previous turns from the conversation in our prompt.

This exmaple includes the whole conversation so far:

```
{% turns %}
```

Each previous turn in the conversation is included, and is formatted somewhat like a screenplay:

```
Therapist: Hi how are you doing?
Client: OK, I suppose
...
```

We can also restrict the context to include just what has been said in the current Step:

```
{% turns 'step' %}
```

Or the last few turns:

```
{% turns n=2 %}
```

This only shows the last 2 turns (2 turns in total, not 2 from each speaker).



### Requesting AI completions

As part of a prompt template, we can ask the AI to respond multiple times.

Each time we want a response, we include a `[[RESPONSE]]` tag:

At minimum, the syntax is: two square braces surrounding a variable name.

This example shows a prompt which makes two completions:

```
Consider the whole conversation so far.
Formulate a response to the client's concerns.
Consider both systemic and individual factors.

[[formulation]]

Now, think about what to say next.
You can only say one thing. Keep it simple

[[therapist_response]]
```

It's important to note that the text generated by `[[formulation]]` will be included when the `[[therapist_response]]` is made, allowing for explicit chain-of-thought type prompting.

#### Styles of response

Optionally, a prefix can be used to guide the style of the AI response.
Presently `think` and `speak` are supported, but more may be added:

```
[[think:response]]
[[speak:response]]
```

A `think` response will be more reflective, longer, and can include notes/plans.
The `speak` response will be more direct, and the AI is requested to use spoken idioms. (These different styles of responses are achieved by adding hints to the call to the AI model.)


#### Classifications

Two prefixes are supported to allow for classifications:

```
[[boolean:response]]
```

And

```
[[pick:response|option1, option2, option3, default=null]]
```



- `pick` guarantees that the response is one of the options provided, after the `|` character, separated by commas.
- `boolean` guarantees that the response is either True or False.

These are useful when making classifications, or for Judgements that determine whether a
step transition should take place.


A multiline version of `pick` is also allowed:

```
[[pick:response
    option1
    option2
    option3
    default=null]]
```



<!---
TODO: Implement this

Finally, advanced users can pass extra parameters to `[[response]]` slots, using the following syntax:

```
[[think:planning]]{max_tokens=50}

[[bool:is_upset]]{allow_null=true}
```
--->



### Using data extracted by Judgements in prompts

Notes made from previous Judgements can be included in the template, using the `data` variable.

For example, we might create a Judgement that extracts and saves data from the conversation at each turn. The Jugdement would be given the recent conversation history and make a series of completions, to extract the client's name (if they give it) and the problem they want to work on.

Once the judgement runs, we can include data it extracts it in the template:

```
You are working with {{ data.extraction_judgement.client_name }}.
```

Here, `extraction_judgement` is the variable-name of the Judgement, and `client_name` is the label given to the completion (e.g. the Judgement prompt includes a completoin like `[[client_name]]`).


If the Judgement identifies a 'problem' we want to work on:

```
{{ data.extraction_judgement.problem }}
```


Alternatively we might use a Judgement to make a clinical summary of
conversation in previous steps. If Judgement variable name is `step_summary`, and the
completion that we want to use is called `short`, then we include that with:

```
{{ data.step_summary.short }}
```






### Including relevant examples (RAG)

TODO: update this

NOTE - THE SYNTAX FOR RAG IS CHANGING AND INCLUDING EXAMPLES ARE CURRENTLY NOT IMPLEMENTED

Examples of good practice on a topic for a given scenario:

```
{% examples 'reflection' %}
{% examples 'a client finding it hard to generate imagery' %}
```


Examples of good practice relevant to something a client said (i.e. dynamically found and included):

```
{% examples data.problem_elicited %}
```


### Other features

#### Comments in templates

TODO: Implement this.

```
\\ This is a comment and won't be visible to the AI model
You are an AI therapist.
Help the client with their problem.
[[speak:response]]

```


#### Splitting prompts and saving tokens with `OBLIVIATE!`

Sometimes, we want to:

A. use an initial prompt to create a response
B. refine the response, using secondary instructions


In part A, we provide the LLM a lot of context.
In part B, we may not need all this context.

To save tokens, we can take the response from part A, and use it as input for part B.
This is done with the `¡OBLIVIATE` tag.

Example:

```
Long context about the history of vampires
Tell me a joke
[[speak:joke]]

¡OBLIVIATE

This is a joke:
{{joke}}

Tell me, is it funny:

[[boolean:funny]]
```

The key here is that when we are deciding if the joke is funny, we don't need the original context, so it's hidden. This speeds up generation and saved cost.


### More examples of prompts

- [Steps and Judgements for the Demo MI intervention](docs/mi/)


- [Step](syntax-exmaple.step)
- [Judgement](syntax-exmaple.judgement)
